# addressee_detector.py
import logging
import time
import torch
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import numpy as np

logger = logging.getLogger(__name__)
model_dir = "Silxxor/Russian-Addressee-detector"

class AddresseeDetector: 
    def __init__(self):
        """The brain police.  Decides if you are worthy of my attention."""

        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        try:
            self.classifier = pipeline(
                "text-classification", 
                model=model_dir, 
                tokenizer=AutoTokenizer.from_pretrained(model_dir),
                device=0 if self.device == "cuda" else -1,
                top_k=None
            )
            logger.info("AddresseeDetector loaded.")
        except Exception as e:
            logger.error(f"Failed to load addressee model: {e}")
            self.classifier = None

        self.last_interaction_time = 0
        
        self.WAKE_WORDS = ["–ª—é—Å–∏", "–∫–æ–º–ø—å—é—Ç–µ—Ä", "–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç", "lucy", "computer", "assistant"]
        self.CONVERSATION_WINDOW = 10.0
        
        self.HIGH_THRESHOLD = 0.75
        self.LOW_THRESHOLD = 0.25

    def predict(self, text):
        """Returns probability (0.0 - 1.0) that text is addressed to Lucy."""
        if not self.classifier:
            return 1.0
        
        results = self.classifier(text)[0]
        
        for res in results:
            if res['label'] == 'LABEL_1':
                return res['score']
            if res['label'] == 'LABEL_0':
                return 1.0 - res['score']
        
        return 0.0

    def should_reply(self, text, time_since_ai_spoke):
        """
        Simple logic: 
        1. Wake word = YES
        2. Within 5s of last AI response = YES (unless model is VERY sure it's not for us)
        3. Cold start = trust the model
        """
        text_lower = text.lower().strip()
        
        # === WAKE WORDS:  Always yes ===
        for word in self.WAKE_WORDS: 
            if word.lower() in text_lower:
                return True
        
        base_score = self.predict(text)
        in_conversation = time_since_ai_spoke < 5.0
        
        if in_conversation:
            # Recently talked = assume they're still talking to us
            # UNLESS model is very confident it's NOT for us (< 0.15)
            if base_score < 0.15:
                logger.info(f"[ACTIVE] score={base_score:.2f} < 0.15 -> NO (model very confident)")
                return False
            else: 
                logger.info(f"[ACTIVE] score={base_score:.2f} within 5s -> YES")
                return True
        else: 
            # Cold start = need model confidence
            threshold = 0.5
            result = base_score >= threshold
            logger.info(f"[COLD] score={base_score:.2f} >= {threshold} -> {result}")
            return result
    
    def shutdown(self):
        """Release GPU memory and cleanup resources."""
        logger.info("üß† AddresseeDetector:  Shutting down...")
        
        if self.classifier is not None:
            # Delete the pipeline and its underlying model
            del self.classifier
            self.classifier = None
        
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        logger.info("üß† AddresseeDetector: Shutdown complete.")

    def __del__(self):
        """Destructor - attempt cleanup if shutdown wasn't called."""
        try: 
            if hasattr(self, 'classifier') and self.classifier is not None: 
                self.shutdown()
        except Exception: 
            pass


if __name__=="__main__":
    from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix

    classifier = AddresseeDetector()

    raw_data = [
        ("–±–ª–∏–Ω, —ç—Ç–æ—Ç –∫–æ—Ñ–µ –ø–æ–ª–Ω–æ–µ –≥–æ–≤–Ω–æ", 0),
        ("–õ—é—Å—è, –∫–æ—Ç–æ—Ä—ã–π —Å–µ–π—á–∞—Å —á–∞—Å?", 1),
        ("–±–ª—è, —è —Ç–∞–∫ —É—Å—Ç–∞–ª", 0),
        ("—ç–π –õ—é—Å—è, –ø–æ–º–æ–≥–∏ –º–Ω–µ", 1),
        ("–∫–æ–¥ –≤–æ–æ–±—â–µ –ø–∏–∑–¥–µ—Ü –∫–∞–∫–æ–π-—Ç–æ", 0),
        ("–õ—é—Å—è, –∫–æ–¥ –ø–æ–ª–Ω—ã–π –ø–∏–∑–¥–µ—Ü, –ø–æ–º–æ–≥–∏ —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è", 1),
        ("–ø—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞ –≤–æ–æ–±—â–µ?", 0),
        ("–π–æ –õ—é—Å—è", 1),
        ("–ø—Ä–∏–≤–µ—Ç –Ω–∞—Ä–æ–¥ / –∫–∞–∫ –¥–µ–ª–∞ –ø–∞—Ü–∞–Ω—ã", 0),
        ("–Ω—É —Ç—ã —Å–∞–º –∑–Ω–∞–µ—à—å –∫–∞–∫ –±—ã–≤–∞–µ—Ç", 0),
        ("—è –¥—É–º–∞—é —Ç–µ–±–µ —Å—Ç–æ–∏—Ç", 0),
        ("—á—Ç–æ –≤–æ–æ–±—â–µ –±–ª—è—Ç—å –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç", 0),
        ("—ç–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–∞–∫ –¥–µ–ª–∞?", 1),
        ("–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –º–æ–∂–µ—à—å –ø–æ–º–æ—á—å –º–Ω–µ —Å —ç—Ç–∏–º —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è?", 1),
        ("–ª–∞–¥–Ω–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç", 1),
        ("–∫–æ–º–ø—å—é—Ç–µ—Ä, –ø–æ–º–æ–≥–∏ –º–Ω–µ", 1),
        ("—ç–π –∫–æ–º–ø—å—é—Ç–µ—Ä", 1),
        ("—Ç–µ–±–µ –Ω–∞–¥–æ –Ω–∞ —ç—Ç–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å", 1), 
        ("–Ω–∞–º –Ω–∞–¥–æ —ç—Ç–æ –ø–æ—á–∏–Ω–∏—Ç—å", 0),
        ("–∫—Ç–æ-–Ω–∏–±—É–¥—å –ø–æ–º–æ–≥–∏—Ç–µ", 0),
        ("–∫—Ç–æ-–Ω–∏–±—É–¥—å –∑–Ω–∞–µ—Ç –ø–æ—á–µ–º—É?", 0),
        ("–º–æ–∂–µ—Ç –∫—Ç–æ –æ–±—ä—è—Å–Ω–∏—Ç?", 0),
        ("–∫—É–¥–∞ —è —ç—Ç–æ –ø–æ–ª–æ–∂–∏–ª?", 0),
        ("–∫–æ–≥–¥–∞ —ç—Ç–æ –±—ã–ª–æ –≤ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞–∑?", 0),
        ("–∫—Ç–æ —ç—Ç–æ —Å–ª–æ–º–∞–ª?", 0),
        ("–∫–∞–∫–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –ª—É—á—à–µ?", 0),
        ("–ø–æ—á–µ–º—É —ç—Ç–æ –¥–µ—Ä—å–º–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç?", 0),
        ("—Ç—ã –Ω–µ –ø–æ–≤–µ—Ä–∏—à—å", 0),
        ("–Ω–∞–º –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏", 0),
        ("—Ç—É—Ç –∫–∞–∫–∞—è-—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞", 0),
        ("—á—Ç–æ-—Ç–æ —Ç—É—Ç –Ω–µ —Ç–∞–∫", 0),
        ("–≤—Å–µ –Ω–∞—Ö—É–π —Å–ª–æ–º–∞–ª–æ—Å—å", 0),
        ("–ø–æ–∫–∞–∂–∏ –ª–æ–≥–∏", 1),
        ("–ø—Ä–æ–≤–µ—Ä—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö", 1),
        ("–∑–∞–ø—É—Å—Ç–∏ —Ç–µ—Å—Ç—ã —Å–Ω–æ–≤–∞", 1),
        ("–æ—Å—Ç–∞–Ω–æ–≤–∏ —Å–µ—Ä–≤–µ—Ä", 1),
        ("–ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏ –≤—Å–µ", 1),
        ("–∑–∞—á–µ–º —è —Ç–∞–∫ —Å–¥–µ–ª–∞–ª?", 0),
        ("–æ —á–µ–º —è –≤–æ–æ–±—â–µ –¥—É–º–∞–ª?", 0),
        ("–∫–∞–∫ —ç—Ç–æ –≤–æ–æ–±—â–µ –∫–æ–≥–¥–∞-—Ç–æ —Ä–∞–±–æ—Ç–∞–ª–æ?", 0),
        ("–∫—É–¥–∞ —è –≤–æ–æ–±—â–µ —Å —ç—Ç–∏–º —à–µ–ª?", 0),
        ("–∫–æ–≥–¥–∞ —ç—Ç–æ –≤—Å–µ —Å–ª–æ–º–∞–ª–æ—Å—å?", 0),
        ("–Ω—É —Ç–∏–ø–∞ –µ—Å—Ç—å —Ç–∞–∫–∞—è —à—Ç—É–∫–∞ —Å...", 0),
        ("–¥–∞, –Ω–æ –ø—Ä–æ–±–ª–µ–º–∞ –≤ —Ç–æ–º —á—Ç–æ", 0),
        ("–æ–∫–µ–π, –∫–æ—Ä–æ—á–µ –≥–æ–≤–æ—Ä—è", 0),
        ("—è –∏–º–µ—é –≤ –≤–∏–¥—É, —Å—É—Ç—å –≤ —Ç–æ–º —á—Ç–æ", 0),
        ("–Ω—É –æ—á–µ–≤–∏–¥–Ω–æ –∂–µ —á—Ç–æ –º—ã –Ω–µ –º–æ–∂–µ–º", 0),
        ("—Ç—ã –ø–æ–Ω–∏–º–∞–µ—à—å –æ —á–µ–º —è?", 1),
        ("–Ω–µ –º–æ–≥—É –ø–æ–≤–µ—Ä–∏—Ç—å –≤ —ç—Ç–æ –¥–µ—Ä—å–º–æ", 0),
        ("–≤—ã —á–µ —Ä–µ–±—è—Ç–∞ –∏–∑–¥–µ–≤–∞–µ—Ç–µ—Å—å", 0),
        ("–æ—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —ç—Ç–æ", 0),
        ("–ø–æ—á–∏–Ω–∏ —ç—Ç–æ—Ç –±–∞—Ä–¥–∞–∫", 1),
        ("–ª–∞–¥–Ω–æ, –ø–æ—Ö—É–π, –∏–¥–µ–º –¥–∞–ª—å—à–µ", 0),
        ("–ø–æ—Ö—É–π, —Å–∞–º —Ä–∞–∑–±–µ—Ä—É—Å—å", 0),
        ("–ª–∞–¥–Ω–æ, –¥–æ–ø—É—Å—Ç–∏–º —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç", 0),
        ("–Ω—É –ª–∞–¥–Ω–æ —Ç–æ–≥–¥–∞", 0),
        ("–ø—Ä–∏–∫–æ–ª—å–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è –±—Ä–æ", 0),
        ("–æ–Ω–∞ –ø–æ–Ω–∏–º–∞–µ—Ç –æ–±—Ä–∞—â–∞—é—Å—å —è –∫ –Ω–µ–π –∏–ª–∏ –Ω–µ—Ç", 0),
        ("–¥–∞, –æ–Ω–∞ —Ä–µ–∞–ª—å–Ω–æ —É–º–Ω–∞—è", 0),
        ("–∏ –æ–Ω–∞ –ø—Ä–∏–∫–æ–ª—å–Ω–∞—è –µ—â–µ", 0),
        ("–æ–Ω–∞ –ø—Ä–æ—Å—Ç–æ –∫–ª–∞—Å—Å–Ω–∞—è", 0),
        ("–¥–∞, –æ–Ω–∞ –ª—É—á—à–∞—è –ø–æ–∫–∞ —á—Ç–æ", 0)
    ]

    test_texts = [x[0] for x in raw_data]
    test_labels = np.array([x[1] for x in raw_data])

    predictions = []
    print(f"Running inference on {len(test_texts)} cases...")

    for text in test_texts:
        pred = classifier.predict(text)
        pred = np.round(pred)
        predictions.append(pred)

    predictions = np.array(predictions)
    accuracy = accuracy_score(test_labels, predictions)
    precision, recall, f1, _ = precision_recall_fscore_support(test_labels, predictions, average='binary', zero_division=0)
    cm = confusion_matrix(test_labels, predictions)

    # 5. Print Report
    print("\n" + "="*50)
    print("ADDRESSEE DETECTOR EVALUATION")
    print("="*50)
    print(f"Accuracy:           {accuracy*100:.2f}%")
    print(f"Precision:          {precision*100:.2f}%")
    print(f"Recall:             {recall*100:.2f}%")
    print(f"F1-Score:           {f1*100:.2f}%")
    print("-" * 50)
    print("Confusion Matrix:")
    print(f"Predicted [0] | Actual [0]: {cm[0][0]} (TN)")
    print(f"Predicted [1] | Actual [0]: {cm[0][1]} (FP)")
    print(f"Predicted [0] | Actual [1]: {cm[1][0]} (FN)")
    print(f"Predicted [1] | Actual [1]: {cm[1][1]} (TP)")
    print("="*50)

    # 6. Show Failures
    print("\nFAILED TEST CASES:")
    has_failures = False
    for i, (text, true_label, pred_label) in enumerate(zip(test_texts, test_labels, predictions)):
        if true_label != pred_label:
            has_failures = True
            t_name = "ADDRESSED" if true_label == 1 else "NOT_ADDRESSED"
            p_name = "ADDRESSED" if pred_label == 1 else "NOT_ADDRESSED"
            print(f"‚úñ '{text}'\n  Expected: {t_name} | Got: {p_name}\n")

    if not has_failures:
        print("All tests passed perfectly!")

    #=================================================================
    print("\n" + "="*70)
    print("THREE-TIER LOGIC ANALYSIS")
    print("="*70)
    print(f"HIGH_THRESHOLD (Tier2 YES): >= {classifier.HIGH_THRESHOLD}")
    print(f"LOW_THRESHOLD (Tier2 NO):   <= {classifier.LOW_THRESHOLD}")
    print(f"AMBIGUOUS ZONE (Tier3):     {classifier.LOW_THRESHOLD} < score < {classifier.HIGH_THRESHOLD}")
    print("="*70 + "\n")
    
    # Test phrases with their expected tier behavior
    test_phrases = [
        # (text, description)
        ("–õ—é—Å–∏, –ø—Ä–∏–≤–µ—Ç!", "Wake word - should be TIER1"),
        ("—ç–π –∫–æ–º–ø—å—é—Ç–µ—Ä", "Wake word - should be TIER1"),
        ("–ø–æ–∫–∞–∂–∏ –ª–æ–≥–∏", "Clear command - likely TIER2-YES or high TIER3"),
        ("–ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä", "Clear command"),
        ("–±–ª–∏–Ω, —ç—Ç–æ—Ç –∫–æ—Ñ–µ –≥–æ–≤–Ω–æ", "Self-talk - should be TIER2-NO"),
        ("–±–ª—è, —è —É—Å—Ç–∞–ª", "Self-talk - should be TIER2-NO"),
        ("–æ–Ω–∞ —Ç–∞–∫–∞—è —É–º–Ω–∞—è", "Talking ABOUT AI - should be TIER2-NO"),
        ("–∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ.. .", "Ambiguous - should be TIER3"),
        ("–¥–∞", "Ambiguous - should be TIER3"),
        ("–Ω–µ—Ç, –Ω–µ —Ç–æ", "Ambiguous - should be TIER3"),
        ("—Ö–º, –ø–æ–Ω—è—Ç–Ω–æ", "Ambiguous - should be TIER3"),
        ("–ø—Ä–æ–¥–æ–ª–∂–∞–π", "Ambiguous command - likely TIER3"),
        ("—Ç—ã –ø–æ–Ω–∏–º–∞–µ—à—å? ", "Ambiguous question - likely TIER3"),
        ("–∫–∞–∫ —É —Ç–µ–±—è –¥–µ–ª–∞?", "Conversational - likely TIER3"),
        ("–∞ —á—Ç–æ –µ—Å–ª–∏ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å?", "Follow-up - likely TIER3"),
    ]
    
    print(f"{'Text':<45} {'Score': >6} {'Tier':<12} {'Cold': >6} {'@1s':>6} {'@5s':>6}")
    print("-"*85)
    
    for text, desc in test_phrases: 
        score = classifier.predict(text)
        
        # Determine tier
        text_lower = text.lower()
        is_wake = any(w in text_lower for w in classifier.WAKE_WORDS)
        
        if is_wake:
            tier = "TIER1-WAKE"
        elif score >= classifier.HIGH_THRESHOLD:
            tier = "TIER2-YES"
        elif score <= classifier.LOW_THRESHOLD:
            tier = "TIER2-NO"
        else:
            tier = "TIER3-AMB"
        
        # Test at different time contexts
        cold_result = classifier.should_reply(text, 100.0)
        at_1s = classifier.should_reply(text, 1.0)
        at_5s = classifier.should_reply(text, 5.0)
        
        cold_str = "‚úÖ" if cold_result else "‚ùå"
        at_1s_str = "‚úÖ" if at_1s else "‚ùå"
        at_5s_str = "‚úÖ" if at_5s else "‚ùå"
        
        print(f"{text:<45} {score:>6.2f} {tier:<12} {cold_str:>6} {at_1s_str:>6} {at_5s_str: >6}")
    
    print("\n" + "="*70)
    print("Legend:  Cold = no recent AI speech | @1s/@5s = seconds since AI spoke")
    print("="*70)


    
    print("\n" + "="*70)
    print("AMBIGUOUS PHRASES:  CONTEXT SENSITIVITY TEST")
    print("="*70)
    print("These phrases are INTENTIONALLY ambiguous.  The model can't know.")
    print("Context (time since AI spoke) should be the deciding factor.")
    print("="*70 + "\n")
    
    ambiguous = [
        "–∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ...",
        "–¥–∞",
        "–Ω–µ—Ç",
        "–ø–æ–Ω—è—Ç–Ω–æ",
        "—Ö–æ—Ä–æ—à–æ",
        "–æ–∫–µ–π",
        "–ø—Ä–æ–¥–æ–ª–∂–∞–π",
        "–¥–∞–ª—å—à–µ",
        "–∞ –ø–æ—Ç–æ–º? ",
        "–∏ —á—Ç–æ? ",
        "—Å–µ—Ä—å–µ–∑–Ω–æ?",
        "–æ–≥–æ",
        "–Ω—É –¥–∞–≤–∞–π",
        "–ø–æ–ø—Ä–æ–±—É–π",
    ]
    
    time_points = [0.5, 1.0, 2.0, 3.0, 5.0, 7.0, 9.0, 15.0]
    
    print(f"{'Phrase':<20}", end="")
    for t in time_points:
        print(f"{t:>5}s", end=" ")
    print(f"{'Score':>7}")
    print("-" * 75)
    
    for phrase in ambiguous:
        score = classifier.predict(phrase)
        print(f"{phrase:<20}", end="")
        
        for t in time_points:
            result = classifier.should_reply(phrase, t)
            symbol = "‚úÖ" if result else "¬∑"  # Using dot for cleaner view
            print(f"{symbol: >5}", end=" ")
        
        print(f"{score:>7.2f}")
    
    print("\n" + "-"*75)
    print("‚úÖ = will reply | ¬∑ = will ignore")
    print(f"Conversation window: {classifier.CONVERSATION_WINDOW}s")


    
    print("\n" + "="*70)
    print("REALISTIC CONVERSATION SIMULATION")
    print("="*70 + "\n")
    
    last_ai_spoke = 0
    
    conversation = [
        # (user_says, delay_seconds, expected_response, scenario_note)
        ("–õ—é—Å–∏, –ø—Ä–∏–≤–µ—Ç!", 0, True, "Wake word starts convo"),
        ("–∫–∞–∫ –¥–µ–ª–∞?", 1.5, True, "Quick follow-up"),
        ("–∞ —á—Ç–æ —Ç—ã —É–º–µ–µ—à—å?", 2.0, True, "Continuing conversation"),
        ("–∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ", 1.0, True, "Short reaction - AMBIGUOUS but recent"),
        ("–ø–æ–∫–∞–∂–∏ –ø—Ä–∏–º–µ—Ä", 1.5, True, "Command in active convo"),
        ("–∞–≥–∞, –ø–æ–Ω—è–ª", 2.0, True, "Confirmation"),
        # User turns away to talk to friend
        ("–í–∞—Å—å, –≥–ª—è–Ω—å —á—Ç–æ –æ–Ω–∞ —É–º–µ–µ—Ç", 5.0, False, "Talking to friend Vasya"),
        ("–¥–∞, –ø—Ä–∏–∫–æ–ª—å–Ω–∞—è —à—Ç—É–∫–∞", 3.0, False, "Still talking to friend"),
        ("–Ω—É –ª–∞–¥–Ω–æ, –ø–æ–π–¥–µ–º", 4.0, False, "Leaving with friend"),
        # Long pause, comes back
        ("–õ—é—Å–∏, –µ—â–µ –≤–æ–ø—Ä–æ—Å", 20.0, True, "Wake word after long pause"),
        ("—Å–ø–∞—Å–∏–±–æ, –≤—Å–µ –ø–æ–Ω—è—Ç–Ω–æ", 2.0, True, "Closing in active convo"),
    ]
    
    for user_text, delay, expected, note in conversation:
        if delay > 0:
            print(f"    ... {delay}s pause ...")
            time.sleep(delay)
        
        if last_ai_spoke == 0:
            time_since_ai = 999
        else: 
            time_since_ai = time.time() - last_ai_spoke
        
        result = classifier.should_reply(user_text, time_since_ai)
        
        status = "‚úÖ" if result == expected else "‚ùå"
        print(f"{status} User: \"{user_text}\"")
        print(f"   ‚è± {time_since_ai:.1f}s since AI | Expected: {expected} | Got: {result}")
        print(f"   üìù {note}")
        
        if result: 
            print(f"   ü§ñ AI responds...")
            last_ai_spoke = time.time()
        print()
